{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmPj-B5drUCs"
   },
   "source": [
    "# **Monk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ynlp1gjJriPt"
   },
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install tensorflow_decision_forests\n",
    "!pip install wurlitzer\n",
    "!pip install scikeras[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTffeKXmrtgz"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# MLP\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Decision Forest\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "# Cross-validation\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, log_loss\n",
    "\n",
    "# Import statistics\n",
    "from statistics import mean, stdev, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQWKNE7xrCxf"
   },
   "outputs": [],
   "source": [
    "# Mount google drive to access data loaded on Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ve6wXsaLy2yq"
   },
   "source": [
    "**Definition of functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0MUIZ9jrrOJ"
   },
   "outputs": [],
   "source": [
    "## Definition of loss/accuracy plot functions\n",
    "def loss_plot(history):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  epochs = range(1, len(loss) + 1)\n",
    "  plt.figure(figsize=(9, 5))\n",
    "  # Training and test loss\n",
    "  plt.plot(epochs, loss, label='Training loss', color='royalblue')\n",
    "  plt.plot(epochs, val_loss, label='Test loss', linestyle='dashed', color='darkorange')\n",
    "  plt.title('Training & Test Loss', fontsize=14)\n",
    "  plt.xlabel('Epochs', fontsize=14)\n",
    "  plt.ylabel('Loss', fontsize=14)\n",
    "  plt.xticks(fontsize=12)\n",
    "  plt.yticks(fontsize=12)\n",
    "  plt.legend(fontsize=14)\n",
    "  plt.show()\n",
    "\n",
    "def accuracy_plot(history):\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  epochs = range(1, len(acc) + 1)\n",
    "  plt.figure(figsize=(9, 5))\n",
    "  # Training and test accuracy\n",
    "  plt.plot(epochs, acc, label='Training acc', color='royalblue')\n",
    "  plt.plot(epochs, val_acc, label='Test acc', linestyle='dashed', color='darkorange')\n",
    "  plt.title('Training & Test Accuracy', fontsize=14)\n",
    "  plt.xlabel('Epochs', fontsize=14)\n",
    "  plt.ylabel('Accuracy', fontsize=14)\n",
    "  plt.xticks(fontsize=12)\n",
    "  plt.yticks(fontsize=12)\n",
    "  plt.legend(fontsize=14)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bh--hcGUy0NK"
   },
   "outputs": [],
   "source": [
    "## Definition of MLP functions\n",
    "\n",
    "# Building and compiling model\n",
    "def build_model(activation, kernel_initializer, optimizer, units=2):\n",
    "  # Define the Model\n",
    "  model = keras.Sequential()\n",
    "  model.add(tf.keras.Input(shape=(17,)))\n",
    "  model.add(layers.Dense(units=units, activation=activation, kernel_initializer=kernel_initializer))\n",
    "  model.add(layers.Dense(units=units, activation=activation, kernel_initializer=kernel_initializer))\n",
    "  model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "  # Compile the model\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "# Training model\n",
    "def train_model(model, X_train, y_train, X_test, y_test, batch_size=32, epochs=500, callbacks=None):\n",
    "  # Fit the model\n",
    "  history = model.fit(X_train,\n",
    "                      y_train,\n",
    "                      validation_data=(X_test, y_test),\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      epochs=epochs,\n",
    "                      callbacks=callbacks)\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKpBQgu-2QKc"
   },
   "outputs": [],
   "source": [
    "## Definition of Random Forest\n",
    "\n",
    "# Building model\n",
    "def create_rf_model(num_trees, max_depth, min_examples, algorithm='RANDOM', num_candidate_attributes=0, verbose=2):\n",
    "    # Define the model\n",
    "    rf_model = tfdf.keras.RandomForestModel(\n",
    "        num_trees=num_trees,\n",
    "        max_depth=max_depth,\n",
    "        min_examples=min_examples,\n",
    "        categorical_algorithm=algorithm,\n",
    "        num_candidate_attributes=num_candidate_attributes,\n",
    "        task=tfdf.keras.Task.CLASSIFICATION,\n",
    "        verbose=verbose)\n",
    "    return rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sv3mOGe94-GY"
   },
   "outputs": [],
   "source": [
    "## Definition of Support Vector Machine\n",
    "def create_svm_model(kernel, C=1, degree=1, gamma='scale', verbose=2):\n",
    "  # Define the model\n",
    "  svm_model = SVC(kernel=kernel,\n",
    "                  C=C,\n",
    "                  degree=degree,\n",
    "                  gamma=gamma,\n",
    "                  verbose=verbose)\n",
    "  return svm_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dkEIm-Ds0nY"
   },
   "source": [
    "---\n",
    "## **Monk 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kURFFDPDtNYY"
   },
   "source": [
    "### **Data preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsxC_ZPJtcdT"
   },
   "source": [
    "**Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQq5rHKHtYZx"
   },
   "outputs": [],
   "source": [
    "# Loading the training dataset MONK-1\n",
    "path = '/content/drive/MyDrive/data/monk+s+problems/monks-1.train'\n",
    "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
    "\n",
    "monk_1_train = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
    "monk_1_train.set_index('ID', inplace=True)\n",
    "monk_1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-MEmhAPuEY9"
   },
   "outputs": [],
   "source": [
    "# Check the first 5 rows\n",
    "monk_1_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgummz1KuEWO"
   },
   "outputs": [],
   "source": [
    "# Count unique values for each column\n",
    "monk_1_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtnVIsBcuG_z"
   },
   "outputs": [],
   "source": [
    "# Count the number of records for the two classes\n",
    "monk_1_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdEKCARutjyv"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding training set\n",
    "X_train_encoded = pd.get_dummies(monk_1_train, columns=col_names[1:-1])\n",
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRZAIHlquLAP"
   },
   "outputs": [],
   "source": [
    "X_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocGBEDfstjtC"
   },
   "outputs": [],
   "source": [
    "# y_train, X_train split\n",
    "y_train_monk1, X_train_monk1 = X_train_encoded['class'], X_train_encoded.iloc[:, 1:]\n",
    "\n",
    "print(f'y shape: {y_train_monk1.shape}')\n",
    "print(f'X shape: {X_train_monk1.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmdsQEbztuW9"
   },
   "source": [
    "**Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDtX3wdottoE"
   },
   "outputs": [],
   "source": [
    "# Loading the test dataset MONK-1\n",
    "path = '/content/drive/MyDrive/data/monk+s+problems/monks-1.test'\n",
    "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
    "\n",
    "monk_1_test = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
    "monk_1_test.set_index('ID', inplace=True)\n",
    "monk_1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdKUUvJkttlS"
   },
   "outputs": [],
   "source": [
    "# Encoding categorical variable\n",
    "monk_1_test_encoded = pd.get_dummies(monk_1_test, columns=col_names[1:-1])\n",
    "monk_1_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_02DR0fttiV"
   },
   "outputs": [],
   "source": [
    "# y_test, X_test\n",
    "y_test_monk1, X_test_monk1 = monk_1_test_encoded['class'], monk_1_test_encoded.iloc[:, 1:]\n",
    "\n",
    "print(f'y shape: {y_test_monk1.shape}')\n",
    "print(f'X shape: {X_test_monk1.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEEtt94cuOEy"
   },
   "source": [
    "### **Multi Layer Perceptron - MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xIhltauttfm"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "mlp1 = build_model(activation='elu',\n",
    "                   kernel_initializer='HeUniform',\n",
    "                   units=2,\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.04))\n",
    "\n",
    "# Fit model\n",
    "mlp1_history = train_model(mlp1, X_train_monk1, y_train_monk1, X_test_monk1, y_test_monk1, batch_size=32, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnLGgMFyttcg"
   },
   "outputs": [],
   "source": [
    "# Loss plot\n",
    "loss_plot(mlp1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kt7__oKGtjqX"
   },
   "outputs": [],
   "source": [
    "# Accuracy plot\n",
    "accuracy_plot(mlp1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RslDlm3j02Ez"
   },
   "outputs": [],
   "source": [
    "# Model evaluation on the training & test set\n",
    "results_TR = mlp1.evaluate(x=X_train_monk1, y=y_train_monk1)\n",
    "print(f\"train loss: {results_TR[0]}, train acc: {results_TR[1]}\")\n",
    "\n",
    "results_TS = mlp1.evaluate(x=X_test_monk1, y=y_test_monk1)\n",
    "print(f\"test loss: {results_TS[0]}, test acc: {results_TS[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5EnAEA602B6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the model multiple times to assess weights initialization influence\n",
    "\n",
    "trials = 5\n",
    "\n",
    "history_list = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "\n",
    "for trial in range(trials):\n",
    "    model = build_model(activation='elu',\n",
    "                        kernel_initializer='HeUniform',\n",
    "                        units=2,\n",
    "                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))\n",
    "    history = train_model(model, X_train_monk1, y_train_monk1, X_test_monk1, y_test_monk1, batch_size=32, epochs=500)\n",
    "    history_list.append(history)\n",
    "    results_train = model.evaluate(x=X_train_monk1, y=y_train_monk1)\n",
    "    results_test = model.evaluate(x=X_test_monk1, y=y_test_monk1)\n",
    "    # train\n",
    "    train_losses.append(results_train[0])\n",
    "    train_accuracies.append(results_train[1])\n",
    "    # test\n",
    "    test_losses.append(results_test[0])\n",
    "    test_accuracies.append(results_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1wq5LSq1ZX2"
   },
   "outputs": [],
   "source": [
    "print('MLP 1 MODEL')\n",
    "print()\n",
    "print('TRAIN ACCURACY')\n",
    "print(f'train max: {np.amax(train_accuracies)}')\n",
    "print(f'train mean: {np.mean(train_accuracies)}')\n",
    "print(f'train median: {np.median(train_accuracies)}')\n",
    "print(f'train variance: {np.var(train_accuracies)}')\n",
    "print()\n",
    "print('TEST ACCURACY')\n",
    "print(f'test max: {np.amax(test_accuracies)}')\n",
    "print(f'test mean: {np.mean(test_accuracies)}')\n",
    "print(f'train median: {np.median(train_accuracies)}')\n",
    "print(f'test variance: {np.var(test_accuracies)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78Zj1F2p1x38"
   },
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rJogB0114Hv"
   },
   "outputs": [],
   "source": [
    "# Convert the dataset to categorical variables otherwise used by the RF as numerical\n",
    "monk_1_train_new = monk_1_train.astype(str)\n",
    "monk_1_test_new = monk_1_test.astype(str)\n",
    "\n",
    "print(monk_1_train_new.dtypes)\n",
    "print(monk_1_test_new.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0XNA2Fd1-gE"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "rf1 = create_rf_model(num_trees=300,\n",
    "                      max_depth=10,\n",
    "                      min_examples=1,\n",
    "                      algorithm='RANDOM',\n",
    "                      num_candidate_attributes=0)\n",
    "\n",
    "# Model assessment on training/test set\n",
    "rf1.compile(metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "rf1.fit(x=tfdf.keras.pd_dataframe_to_tf_dataset(monk_1_train_new, label='class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UlSL1nW4LDM"
   },
   "outputs": [],
   "source": [
    "# Summary of the model\n",
    "rf1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vHSPV0x4K36"
   },
   "outputs": [],
   "source": [
    "# Training loss & accuracy\n",
    "print('TRAINING:\\n')\n",
    "evaluation_TR = rf1.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_1_train_new, label='class'), return_dict=True)\n",
    "\n",
    "for name, value in evaluation_TR.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8DMiWb54kad"
   },
   "outputs": [],
   "source": [
    "# Test loss & accuracy\n",
    "print('TEST:\\n')\n",
    "evaluation_TS = rf1.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_1_test_new, label='class'), return_dict=True)\n",
    "\n",
    "for name, value in evaluation_TS.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn8xdzB941r2"
   },
   "source": [
    "### **Support Vector Machine - SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIXgD_-j46v_"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "svm1 = create_svm_model(kernel='poly',\n",
    "                        C=3,\n",
    "                        degree=2,\n",
    "                        gamma='scale')\n",
    "# Train the model\n",
    "svm1.fit(X_train_monk1, y_train_monk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3kdOM2z5YMM"
   },
   "outputs": [],
   "source": [
    "# Model assessment on training & test set\n",
    "y_pred_TR = svm1.predict(X_train_monk1)\n",
    "Accuracy_TR = accuracy_score(y_train_monk1, y_pred_TR)\n",
    "\n",
    "y_pred_TS = svm1.predict(X_test_monk1)\n",
    "Accuracy_TS = accuracy_score(y_test_monk1, y_pred_TS)\n",
    "\n",
    "print(f'Train Accuracy: {Accuracy_TR}')\n",
    "print(f'Test Accuracy: {Accuracy_TS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz9sQVzvs0dc"
   },
   "source": [
    "---\n",
    "## **Monk 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJHpVJqv6LV0"
   },
   "source": [
    "### **Data preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gklZfUyk6MDV"
   },
   "source": [
    "**Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d043AmGV6ONB"
   },
   "outputs": [],
   "source": [
    "# Loading the training dataset MONK-2\n",
    "path = '/content/drive/MyDrive/data/monk+s+problems/monks-2.train'\n",
    "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
    "\n",
    "monk_2_train = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
    "monk_2_train.set_index('ID', inplace=True)\n",
    "monk_2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OY13ivWh6OED"
   },
   "outputs": [],
   "source": [
    "# Check the first 5 rows\n",
    "monk_2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rewWuMU6N83"
   },
   "outputs": [],
   "source": [
    "# Count unique values for each column\n",
    "monk_2_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OkjxXTc6Wiv"
   },
   "outputs": [],
   "source": [
    "# Count the number of records for the two classes\n",
    "monk_2_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3CY7iE56Wf7"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding training set\n",
    "X_train_encoded = pd.get_dummies(monk_2_train, columns=col_names[1:-1])\n",
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wU0JalV6Wcw"
   },
   "outputs": [],
   "source": [
    "X_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Kv4r2XN6bAD"
   },
   "outputs": [],
   "source": [
    "# y_train, X_train split\n",
    "y_train_monk2, X_train_monk2 = X_train_encoded['class'], X_train_encoded.iloc[:, 1:]\n",
    "\n",
    "print(f'y shape: {y_train_monk2.shape}')\n",
    "print(f'X shape: {X_train_monk2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjckSQQy6b_P"
   },
   "source": [
    "**Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4HcdSyC6dYm"
   },
   "outputs": [],
   "source": [
    "# Loading the test dataset MONK-2\n",
    "path = '/content/drive/MyDrive/data/monk+s+problems/monks-2.test'\n",
    "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
    "\n",
    "monk_2_test = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
    "monk_2_test.set_index('ID', inplace=True)\n",
    "monk_2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqACO-1X6d5c"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding test set\n",
    "X_test_encoded = pd.get_dummies(monk_2_test, columns=col_names[1:-1])\n",
    "X_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ndi-DHBj6d2s"
   },
   "outputs": [],
   "source": [
    "X_test_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmqajX616h-b"
   },
   "outputs": [],
   "source": [
    "# y_test, X_test split\n",
    "y_test_monk2, X_test_monk2 = X_test_encoded['class'], X_test_encoded.iloc[:, 1:]\n",
    "\n",
    "print(f'y shape: {y_test_monk2.shape}')\n",
    "print(f'X shape: {X_test_monk2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLiP8yUz6jNu"
   },
   "source": [
    "### **Multi Layer Perceptron - MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xmhy2zQ86rfk"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "mlp2 = build_model(activation='elu',\n",
    "                   kernel_initializer='RandomUniform',\n",
    "                   units=2,\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))\n",
    "\n",
    "# Fit model\n",
    "mlp2_history = train_model(mlp2, X_train_monk2, y_train_monk2, X_test_monk2, y_test_monk2, batch_size=32, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psqoQHhu6sM3"
   },
   "outputs": [],
   "source": [
    "# Loss plot\n",
    "loss_plot(mlp2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUeMNUUN6uJ7"
   },
   "outputs": [],
   "source": [
    "# Accuracy plot\n",
    "accuracy_plot(mlp2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDp-Ur4_68WZ"
   },
   "outputs": [],
   "source": [
    "# Model evaluation on the training & test set\n",
    "results_TR = mlp2.evaluate(x=X_train_monk2, y=y_train_monk2)\n",
    "print(f\"train loss: {results_TR[0]}, train acc: {results_TR[1]}\")\n",
    "\n",
    "results_TS = mlp2.evaluate(x=X_test_monk2, y=y_test_monk2)\n",
    "print(f\"test loss: {results_TS[0]}, test acc: {results_TS[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouYxhTJd68S_"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the model multiple times to assess weights initialization influence\n",
    "\n",
    "trials = 5\n",
    "\n",
    "history_list = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "\n",
    "for trial in range(trials):\n",
    "    model = build_model(activation='elu',\n",
    "                        kernel_initializer='RandomUniform',\n",
    "                        units=2,\n",
    "                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))\n",
    "    history = train_model(model, X_train_monk2, y_train_monk2, X_test_monk2, y_test_monk2, batch_size=32, epochs=500)\n",
    "    history_list.append(history)\n",
    "    results_train = model.evaluate(x=X_train_monk2, y=y_train_monk2)\n",
    "    results_test = model.evaluate(x=X_test_monk2, y= y_test_monk2)\n",
    "    # train\n",
    "    train_losses.append(results_train[0])\n",
    "    train_accuracies.append(results_train[1])\n",
    "    # test\n",
    "    test_losses.append(results_test[0])\n",
    "    test_accuracies.append(results_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxr-Xvrv7gcn"
   },
   "outputs": [],
   "source": [
    "print('MLP 2 MODEL')\n",
    "print()\n",
    "print('TRAIN ACCURACY')\n",
    "print(f'train max: {np.amax(train_accuracies)}')\n",
    "print(f'train mean: {np.mean(train_accuracies)}')\n",
    "print(f'train median: {np.median(train_accuracies)}')\n",
    "print(f'train variance: {np.var(train_accuracies)}')\n",
    "print()\n",
    "print('TEST ACCURACY')\n",
    "print(f'test max: {np.amax(test_accuracies)}')\n",
    "print(f'test mean: {np.mean(test_accuracies)}')\n",
    "print(f'train median: {np.median(train_accuracies)}')\n",
    "print(f'test variance: {np.var(test_accuracies)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jqn9bRGD6tx_"
   },
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXlOugs36xQZ"
   },
   "outputs": [],
   "source": [
    "# Convert the dataset to categorical variables otherwise used by the RF as numerical\n",
    "monk_2_train_new = monk_2_train.astype(str)\n",
    "monk_2_test_new = monk_2_test.astype(str)\n",
    "\n",
    "print(monk_2_train_new.dtypes)\n",
    "print(monk_2_test_new.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AoKmZlI8c8c"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "rf2 = create_rf_model(num_trees=200,\n",
    "                      max_depth=15,\n",
    "                      min_examples=1,\n",
    "                      algorithm='RANDOM',\n",
    "                      num_candidate_attributes=0)\n",
    "\n",
    "# Model assessment on training/test set\n",
    "rf2.compile(metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "rf2.fit(x=tfdf.keras.pd_dataframe_to_tf_dataset(monk_2_train_new, label='class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hlb8gmy-8c5b"
   },
   "outputs": [],
   "source": [
    "# Summary of the model\n",
    "rf2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmQ4uYgZ8pbd"
   },
   "outputs": [],
   "source": [
    "# Training loss & accuracy\n",
    "print('TRAINING:\\n')\n",
    "evaluation_TR = rf2.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_2_train_new, label='class'), return_dict=True)\n",
    "\n",
    "for name, value in evaluation_TR.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wy0PW40Q8pYP"
   },
   "outputs": [],
   "source": [
    "# Test loss & accuracy\n",
    "print('TEST:\\n')\n",
    "evaluation_TS = rf2.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_2_test_new, label='class'), return_dict=True)\n",
    "\n",
    "for name, value in evaluation_TS.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVTErATw6xrn"
   },
   "source": [
    "### **Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pd4e4F28-S3"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "svm2 = create_svm_model(kernel='poly',\n",
    "                        C=15,\n",
    "                        degree=2,\n",
    "                        gamma='scale')\n",
    "# Train the model\n",
    "svm2.fit(X_train_monk2, y_train_monk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJAgwLxf89-q"
   },
   "outputs": [],
   "source": [
    "# Model assessment on training & test set\n",
    "y_pred_TR = svm2.predict(X_train_monk2)\n",
    "Accuracy_TR = accuracy_score(y_train_monk2,y_pred_TR)\n",
    "\n",
    "y_pred_TS = svm2.predict(X_test_monk2)\n",
    "Accuracy_TS = accuracy_score(y_test_monk2, y_pred_TS)\n",
    "\n",
    "print(f'Train Accuracy: {Accuracy_TR}')\n",
    "print(f'Test Accuracy: {Accuracy_TS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCso8lEEs0TU"
   },
   "source": [
    "---\n",
    "## **Monk 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2TkZ48N_Se5"
   },
   "source": [
    "### **Data preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvZCaB_W_Tvf"
   },
   "source": [
    "**Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VRpHC-r_YKP"
   },
   "outputs": [],
   "source": [
    "# Loading the training dataset MONK-3\n",
    "path = '/content/drive/MyDrive/data/monk+s+problems/monks-3.train'\n",
    "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
    "\n",
    "monk_3_train = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
    "monk_3_train.set_index('ID', inplace=True)\n",
    "monk_3_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7bL_JQT_ayL"
   },
   "outputs": [],
   "source": [
    "# Check the first 5 rows\n",
    "monk_3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lViZb5rM_auo"
   },
   "outputs": [],
   "source": [
    "# Count unique values for each column\n",
    "monk_3_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lneFiNtg_arB"
   },
   "outputs": [],
   "source": [
    "# Count the number of records for the two classes\n",
    "monk_3_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sp85GZSS_anX"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding training set\n",
    "X_design_encoded = pd.get_dummies(monk_3_train, columns=col_names[1:-1])\n",
    "X_design_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9V8yvqhS_fw4"
   },
   "outputs": [],
   "source": [
    "X_design_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XuQBvk-_fqL"
   },
   "outputs": [],
   "source": [
    "# y_train, X_train split\n",
    "y_design_monk3, X_design_monk3 = X_design_encoded['class'], X_design_encoded.iloc[:, 1:]\n",
    "\n",
    "print(f'y shape: {y_design_monk3.shape}')\n",
    "print(f'X shape: {X_design_monk3.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpPZuHDT_WJl"
   },
   "source": [
    "**Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaRcoKPA_Xuj"
   },
   "outputs": [],
   "source": [
    "# Loading the test dataset MONK-3\n",
    "path = '/content/drive/MyDrive/data/monk+s+problems/monks-3.test'\n",
    "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
    "\n",
    "monk_3_test = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
    "monk_3_test.set_index('ID', inplace=True)\n",
    "monk_3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ciHsz6hf_mRH"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding test set\n",
    "X_test_encoded = pd.get_dummies(monk_3_test, columns=col_names[1:-1])\n",
    "X_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5ldI84y_mN5"
   },
   "outputs": [],
   "source": [
    "X_test_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEj4zxMH_qho"
   },
   "outputs": [],
   "source": [
    "# y_test, X_test split\n",
    "y_test_monk3, X_test_monk3 = X_test_encoded['class'], X_test_encoded.iloc[:, 1:]\n",
    "\n",
    "print(f'y shape: {y_test_monk3.shape}')\n",
    "print(f'X shape: {X_test_monk3.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm73C4pl_v7L"
   },
   "source": [
    "### **Multi Layer Perceptron - MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xa78mLHg_qdy"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "mlp3 = build_model(activation='elu',\n",
    "                   kernel_initializer='HeUniform',\n",
    "                   units=2,\n",
    "                   optimizer=tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.01))\n",
    "\n",
    "# Fit model\n",
    "mlp3_history = train_model(mlp3, X_design_monk3, y_design_monk3, X_test_monk3, y_test_monk3, batch_size=32, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP8DwmVpAHcn"
   },
   "outputs": [],
   "source": [
    "# Loss plot\n",
    "loss_plot(mlp3_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HDnCzHlAHY5"
   },
   "outputs": [],
   "source": [
    "# Accuracy plot\n",
    "accuracy_plot(mlp3_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAFssxOLAHVM"
   },
   "outputs": [],
   "source": [
    "# Model evaluation on the training & test set\n",
    "results_TR = mlp3.evaluate(x=X_design_monk3, y=y_design_monk3)\n",
    "print(f\"train loss: {results_TR[0]}, train acc: {results_TR[1]}\")\n",
    "\n",
    "results_TS = mlp3.evaluate(x=X_test_monk3, y=y_test_monk3)\n",
    "print(f\"test loss: {results_TS[0]}, test acc: {results_TS[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLi8CBLvAHRP"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the model multiple times to assess weights initialization influence\n",
    "\n",
    "trials = 5\n",
    "\n",
    "history_list = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "\n",
    "for trial in range(trials):\n",
    "    model = build_model(activation='elu',\n",
    "                        kernel_initializer='HeUniform',\n",
    "                        units=2,\n",
    "                        optimizer=tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.01))\n",
    "    history = train_model(model, X_design_monk3, y_design_monk3, X_test_monk3, y_test_monk3, batch_size=64, epochs=500)\n",
    "    results_train = model.evaluate(x=X_design_monk3, y=y_design_monk3)\n",
    "    results_test = model.evaluate(x=X_test_monk3, y=y_test_monk3)\n",
    "    history_list.append(history)\n",
    "    # train\n",
    "    train_losses.append(results_train[0])\n",
    "    train_accuracies.append(results_train[1])\n",
    "    # test\n",
    "    test_losses.append(results_test[0])\n",
    "    test_accuracies.append(results_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Mp11_zUAHN3"
   },
   "outputs": [],
   "source": [
    "print('MLP 3 MODEL')\n",
    "print()\n",
    "print('TRAIN ACCURACY')\n",
    "print(f'train max: {np.amax(train_accuracies)}')\n",
    "print(f'train mean: {np.mean(train_accuracies)}')\n",
    "print(f'train median: {np.median(train_accuracies)}')\n",
    "print(f'train variance: {np.var(train_accuracies)}')\n",
    "print()\n",
    "print('TEST ACCURACY')\n",
    "print(f'test max: {np.amax(test_accuracies)}')\n",
    "print(f'test mean: {np.mean(test_accuracies)}')\n",
    "print(f'train median: {np.median(train_accuracies)}')\n",
    "print(f'test variance: {np.var(test_accuracies)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrekRJjcBmtu"
   },
   "source": [
    "### **Multi Layer Perceptron - MLP (Regularization & Early stopping)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrafctZEDZRR"
   },
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1RWbBmQDZM-"
   },
   "outputs": [],
   "source": [
    "# Accuracy on individual fold\n",
    "accuracy_per_fold = []\n",
    "\n",
    "# Number of epochs\n",
    "epochs_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Run a K-folds cross-validation\n",
    "for  fold_idx, (train_indices, val_indices) in enumerate(kfold.split(X_design_monk3, y_design_monk3)):\n",
    "  print(f\"Running fold {fold_idx+1}\")\n",
    "\n",
    "  # Extract the training and validation examples\n",
    "  X_train_fold , y_train_fold = X_design_monk3.iloc[train_indices, :], y_design_monk3.iloc[train_indices]\n",
    "  X_val_fold , y_val_fold = X_design_monk3.iloc[val_indices, :], y_design_monk3.iloc[val_indices]\n",
    "\n",
    "  # Build model\n",
    "  model=build_model(units=2,\n",
    "                    activation='elu',\n",
    "                    kernel_initializer='HeUniform',\n",
    "                    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.7, weight_decay=0.01))\n",
    "\n",
    "  # Train the model\n",
    "  history = model.fit(X_train_fold,\n",
    "                      y_train_fold,\n",
    "                      validation_data=(X_val_fold, y_val_fold),\n",
    "                      batch_size=64,\n",
    "                      epochs=1000,\n",
    "                      callbacks=[early_stopping],\n",
    "                      verbose=0)\n",
    "\n",
    "  # Evaluate the model\n",
    "  accuracy = model.evaluate(x=X_val_fold, y=y_val_fold)[1]\n",
    "  n_epochs = len(history.history['val_accuracy'])\n",
    "  print(f'val_accuracy: {accuracy}')\n",
    "  print(f'n_epochs: {n_epochs}')\n",
    "  accuracy_per_fold.append(accuracy)\n",
    "  epochs_per_fold.append(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwDo5E6HDZIa"
   },
   "outputs": [],
   "source": [
    "# Printing results\n",
    "print(f\"Mean Accuracy: {mean(accuracy_per_fold)}\")\n",
    "print(f\"Stdev Accuracy: {stdev(accuracy_per_fold)}\")\n",
    "print(f'Median epochs: {median(sorted(epochs_per_fold))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bd72bMcVmU65"
   },
   "outputs": [],
   "source": [
    "model_reg = build_model(activation='elu',\n",
    "                     kernel_initializer='HeUniform',\n",
    "                     units=2,\n",
    "                     optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.7, weight_decay=0.01)\n",
    "                     )\n",
    "\n",
    "history_reg = train_model(model_reg,\n",
    "                          X_design_monk3,\n",
    "                          y_design_monk3,\n",
    "                          X_test_monk3,\n",
    "                          y_test_monk3,\n",
    "                          batch_size=32,\n",
    "                          epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvI-cubYmVEh"
   },
   "outputs": [],
   "source": [
    "loss_plot(history_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODi5GRQCmVMx"
   },
   "outputs": [],
   "source": [
    "accuracy_plot(history_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EptAHcETmVTv"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Split design into train and validation sets\n",
    "train, val = train_test_split(X_design_encoded, test_size=0.30, shuffle=True, random_state=42)\n",
    "print(f'train shape: {train.shape}')\n",
    "print(f'val shape: {val.shape}')\n",
    "\n",
    "# y_test, X_test split\n",
    "y_train, X_train = train['class'], train.iloc[:, 1:]\n",
    "y_val, X_val = val['class'], val.iloc[:, 1:]\n",
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}, y_val shape: {y_val.shape}')\n",
    "\n",
    "trials = 5\n",
    "\n",
    "history_list = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "\n",
    "for trial in range(trials):\n",
    "    model = build_model(activation='elu',\n",
    "                        kernel_initializer='HeUniform',\n",
    "                        units=2,\n",
    "                        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.7, weight_decay=0.01))\n",
    "    history = train_model(model, X_train, y_train, X_val, y_val, batch_size=32, epochs=500, callbacks=[early_stopping])\n",
    "    history_list.append(history)\n",
    "    results_train = model.evaluate(x=X_train, y=y_train)\n",
    "    results_val = model.evaluate(x=X_val, y=y_val)\n",
    "    results_test = model.evaluate(x=X_test_monk3, y=y_test_monk3)\n",
    "    # train\n",
    "    train_losses.append(results_train[0])\n",
    "    train_accuracies.append(results_train[1])\n",
    "    # val\n",
    "    val_losses.append(results_val[0])\n",
    "    val_accuracies.append(results_val[1])\n",
    "    # test\n",
    "    test_losses.append(results_test[0])\n",
    "    test_accuracies.append(results_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6B4DUiSuneGr"
   },
   "outputs": [],
   "source": [
    "print('MODEL REGULARIZATION + EARLY STOPPING')\n",
    "print()\n",
    "print('TRAIN ACCURACY')\n",
    "print(f'train max: {np.amax(train_accuracies)}')\n",
    "print(f'train mean: {np.mean(train_accuracies)}')\n",
    "print(f'train median: {np.median(train_accuracies)}')\n",
    "print(f'train variance: {np.var(train_accuracies)}')\n",
    "print()\n",
    "\n",
    "print('VAL ACCURACY')\n",
    "print(f'val max: {np.amax(val_accuracies)}')\n",
    "print(f'val mean: {np.mean(val_accuracies)}')\n",
    "print(f'val median: {np.median(val_accuracies)}')\n",
    "print(f'val variance: {np.var(val_accuracies)}')\n",
    "print()\n",
    "\n",
    "\n",
    "print('TEST ACCURACY')\n",
    "print(f'test max: {np.amax(test_accuracies)}')\n",
    "print(f'test mean: {np.mean(test_accuracies)}')\n",
    "print(f'test median: {np.median(test_accuracies)}')\n",
    "print(f'test variance: {np.var(test_accuracies)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQy7Pz41_2ub"
   },
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_xw3TB-_mKY"
   },
   "outputs": [],
   "source": [
    "# Convert the dataset to categorical variables otherwise used by the RF as numerical\n",
    "monk_3_train_new = monk_3_train.astype(str)\n",
    "monk_3_test_new = monk_3_test.astype(str)\n",
    "\n",
    "print(monk_3_train_new.dtypes)\n",
    "print(monk_3_test_new.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-C0VeBq-n898"
   },
   "outputs": [],
   "source": [
    "# Validation accuracy on the individual folds.\n",
    "accuracy_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Run a 10-folds cross-validation.\n",
    "for  fold_idx, (train_indices, val_indices) in enumerate(kfold.split(X_design_monk3, y_design_monk3)):\n",
    "  print(f\"Running fold {fold_idx+1}\")\n",
    "\n",
    "  # Extract the training and testing examples.\n",
    "  train_fold = monk_3_train_new.iloc[train_indices, :].astype(str)\n",
    "  val_fold = monk_3_train_new.iloc[val_indices, :].astype(str)\n",
    "\n",
    "  # Specify the model\n",
    "  model = create_rf_model(num_trees=200,\n",
    "                          max_depth=30,\n",
    "                          min_examples=15,\n",
    "                          num_candidate_attributes=0,\n",
    "                          algorithm= 'RANDOM',\n",
    "                          verbose=0)\n",
    "\n",
    "  model.compile(metrics=[\"accuracy\"])\n",
    "\n",
    "  # Train the model\n",
    "  model.fit(x=tfdf.keras.pd_dataframe_to_tf_dataset(train_fold, label='class'))\n",
    "\n",
    "  # Evaluate the model.\n",
    "  accuracy = model.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(val_fold, label='class'), return_dict=True)['accuracy']\n",
    "  print(f'val_accuracy: {accuracy}')\n",
    "  accuracy_per_fold.append(accuracy)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean(accuracy_per_fold)}\")\n",
    "print(f\"Stdev Accuracy: {stdev(accuracy_per_fold)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_IqBH5nAi_d"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "rf3 = create_rf_model(num_trees=200,\n",
    "                      max_depth=30,\n",
    "                      min_examples=15,\n",
    "                      algorithm='RANDOM',\n",
    "                      num_candidate_attributes=0)\n",
    "\n",
    "# Model assessment on training/test set\n",
    "rf3.compile(metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "rf3.fit(x=tfdf.keras.pd_dataframe_to_tf_dataset(monk_3_train_new, label='class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_w-hbR9AnGa"
   },
   "outputs": [],
   "source": [
    "# Summary of the model\n",
    "rf3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBwIpr1NAm7c"
   },
   "outputs": [],
   "source": [
    "# Training loss/accuracy\n",
    "print('TRAINING:\\n')\n",
    "evaluation_TR = rf3.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_3_train_new, label='class'), return_dict=True)\n",
    "\n",
    "for name, value in evaluation_TR.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoC1mH8wAi8D"
   },
   "outputs": [],
   "source": [
    "# Test loss/accuracy\n",
    "print('TEST:\\n')\n",
    "evaluation_TS = rf3.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_3_test_new, label='class'), return_dict=True)\n",
    "\n",
    "for name, value in evaluation_TS.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4ysXAq0_3N1"
   },
   "source": [
    "### **Support Vector Machine - SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AW7WE0qoiY2"
   },
   "outputs": [],
   "source": [
    "# Stratified K-Fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Specify the model\n",
    "model = create_svm_model(kernel='rbf',\n",
    "                          C=1,\n",
    "                          gamma='scale')\n",
    "\n",
    "val_scores = cross_val_score(model, X_design_monk3, y_design_monk3, cv=kfold, scoring=make_scorer(accuracy_score))\n",
    "print(val_scores)\n",
    "print(f'val_mean: {mean(val_scores)}')\n",
    "print(f'val_stdev: {stdev(val_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxclWDPT_mHU"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "svm3 = create_svm_model(kernel='rbf',\n",
    "                          C=1,\n",
    "                          gamma='scale')\n",
    "\n",
    "# Train the model\n",
    "svm3.fit(X_design_monk3, y_design_monk3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSpCh27TA0et"
   },
   "outputs": [],
   "source": [
    "# Model assessment on training/test set\n",
    "y_pred_TR = svm3.predict(X_design_monk3)\n",
    "Accuracy_TR = accuracy_score(y_design_monk3, y_pred_TR)\n",
    "\n",
    "y_pred_TS = svm3.predict(X_test_monk3)\n",
    "Accuracy_TS = accuracy_score(y_test_monk3, y_pred_TS)\n",
    "\n",
    "print(f'Train Accuracy: {Accuracy_TR}')\n",
    "print(f'Test Accuracy: {Accuracy_TS}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
