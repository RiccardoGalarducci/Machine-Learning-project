{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C75c9hjwD6pW"
   },
   "source": [
    "# **Random Forest (ML-CUP22)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BmQ1LKog-kV"
   },
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install tensorflow_decision_forests\n",
    "!pip install dtreeviz\n",
    "!pip install keras-tuner -U -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vaq1fWX8hJEh"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean, stdev\n",
    "\n",
    "# Decision Forest\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "# Visualize the decision forest\n",
    "import dtreeviz\n",
    "\n",
    "# keras_tuner for GridSearch\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEKAcoksDeYR"
   },
   "outputs": [],
   "source": [
    "# Mount google drive to access data loaded on Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25ZVgVDDhPpF"
   },
   "source": [
    "**Definition of Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQu2lSlchN5H"
   },
   "outputs": [],
   "source": [
    "## Definition of Mean Euclidean Error (MEE): metric used for performance evaluation of the model\n",
    "def MEE(y_true, y_pred):\n",
    "  eucl_norm = tf.norm(y_true - y_pred, ord='euclidean', axis=1)\n",
    "  return tf.reduce_mean(eucl_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0SzWghGFnUh"
   },
   "source": [
    "---\n",
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtEv2E_3Foq8"
   },
   "outputs": [],
   "source": [
    "# Loading the training dataset ML-CUP\n",
    "path = '/content/drive/MyDrive/data/Data_CUP/ML-CUP22-TR.csv'\n",
    "col_names = ['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'x', 'y']\n",
    "\n",
    "data = pd.read_csv(path, names=col_names, comment='#')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0QhlsqEFovJ"
   },
   "outputs": [],
   "source": [
    "# Check the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UXtJO2uJ9uh"
   },
   "outputs": [],
   "source": [
    "# Check for NaN values\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GUJAkT6Mdf8"
   },
   "outputs": [],
   "source": [
    "# Split data into design (85%) and test (15%) sets\n",
    "design, test = train_test_split(data, test_size=0.15, shuffle=True, random_state=42)\n",
    "print(f'design shape: {design.shape}')\n",
    "print(f'test shape: {test.shape}')\n",
    "\n",
    "# Split design data into train (80%) and validation (20%) sets\n",
    "train, val = train_test_split(design, test_size=0.20, shuffle=True, random_state=42)\n",
    "print(f'train shape: {train.shape}')\n",
    "print(f'val shape: {val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qaJ0fwft7h-q"
   },
   "outputs": [],
   "source": [
    "# Descriptive statistics on design data\n",
    "design.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8P7TQw5H_hQ"
   },
   "outputs": [],
   "source": [
    "# X_design, y_design split\n",
    "X_design , y_design = design.iloc[:, :-2], design.loc[:, ['x', 'y']]\n",
    "print(f'X_design shape: {X_design.shape}')\n",
    "print(f'y_design shape: {y_design.shape}')\n",
    "print()\n",
    "\n",
    "# X_train, y_train split\n",
    "X_train , y_train = train.iloc[:, :-2], train.loc[:, ['x', 'y']]\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print()\n",
    "\n",
    "# X_val, y_val split\n",
    "X_val , y_val = val.iloc[:, :-2], val.loc[:, ['x', 'y']]\n",
    "print(f'X_val shape: {X_val.shape}')\n",
    "print(f'y_val shape: {y_val.shape}')\n",
    "print()\n",
    "\n",
    "# X_test, y_test split\n",
    "X_test , y_test = test.iloc[:, :-2], test.loc[:, ['x', 'y']]\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybCjXsf32Hja"
   },
   "outputs": [],
   "source": [
    "# RandomForestModel works with tf.data.Dataset\n",
    "# In Multitask the tf.dataset label (i.e. the second element of the dataset) should be a dictionary of label_key:label_values\n",
    "\n",
    "# Prepare Design set\n",
    "y_design_dict = {\n",
    "    'x': y_design['x'].values,\n",
    "    'y': y_design['y'].values\n",
    "    }\n",
    "design_dataset = tf.data.Dataset.from_tensor_slices((X_design, y_design_dict)).batch(512)\n",
    "\n",
    "# Prepare Training set\n",
    "y_train_dict = {\n",
    "    'x': y_train['x'].values,\n",
    "    'y': y_train['y'].values\n",
    "    }\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train_dict)).batch(512)\n",
    "\n",
    "# Prepare Validation set\n",
    "y_val_dict = {\n",
    "    'x': y_val['x'].values,\n",
    "    'y': y_val['y'].values\n",
    "    }\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val_dict)).batch(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gA9nN2JzFgqO"
   },
   "source": [
    "---\n",
    "## **Preliminary Experimental Phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBgUFy4SBgRB"
   },
   "outputs": [],
   "source": [
    "# Multitask Regression (model with multiple outputs trained to predict different labels)\n",
    "mulitask = [tfdf.keras.MultiTaskItem(label=t, task=tfdf.keras.Task.REGRESSION) for t in ['x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOm5YO8UOLON"
   },
   "outputs": [],
   "source": [
    "# Configure the model\n",
    "model = tfdf.keras.RandomForestModel(multitask=mulitask,\n",
    "                                     winner_take_all=False,\n",
    "                                     max_depth=30,\n",
    "                                     num_trees=300\n",
    "                                     )\n",
    "\n",
    "# Compile the model\n",
    "model.compile(metrics=[MEE, 'mse'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset)\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRlBbPMSOcZ-"
   },
   "outputs": [],
   "source": [
    "# x_mee, y_mee\n",
    "evaluation = model.evaluate(val_dataset, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlknlCnldzPt"
   },
   "outputs": [],
   "source": [
    "# Predict the validation dataset\n",
    "val_pred = model.predict(X_val.values)\n",
    "val_pred = pd.DataFrame({k:v.ravel() for k, v in val_pred.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MopFKD-9g55S"
   },
   "outputs": [],
   "source": [
    "# Mean Euclidean Error\n",
    "y_true = tf.convert_to_tensor(y_val, dtype=tf.double)\n",
    "y_pred = tf.convert_to_tensor(val_pred, dtype=tf.double)\n",
    "\n",
    "mee = MEE(y_true, y_pred)\n",
    "print(mee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bu4scGKl3nX"
   },
   "source": [
    "---\n",
    "## **GridSearch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix6qME_k-UQr"
   },
   "source": [
    "### **Coarse-grained GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QsE5WglE-vT2"
   },
   "outputs": [],
   "source": [
    "# Multitask Regression\n",
    "mulitask = [tfdf.keras.MultiTaskItem(label=t, task=tfdf.keras.Task.REGRESSION) for t in ['x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83Lzsk3eZcP1"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  model = tfdf.keras.RandomForestModel(\n",
    "      min_examples=hp.Choice(\"min_examples\", [2, 5, 10]),\n",
    "      categorical_algorithm=hp.Choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"]),\n",
    "      max_depth=hp.Choice(\"max_depth\", [5, 15, 30]),\n",
    "      num_candidate_attributes_ratio=hp.Choice(\"num_candidate_attributes_ratio\", [-1.0, 0.2, 0.5]),\n",
    "      num_trees = hp.Choice(\"num_trees\", [100, 500, 1000]),\n",
    "      winner_take_all=hp.Boolean(\"winner_take_all\"),\n",
    "      multitask=mulitask\n",
    "  )\n",
    "  # Optimize the model MEE as computed on the validation dataset\n",
    "  model.compile(metrics=[MEE])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfxSlrig-Zt5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define Keras Tuner\n",
    "keras_tuner = kt.GridSearch(\n",
    "    build_model,\n",
    "    # Minimizing the sum of all the objectives to minimize\n",
    "    objective=[kt.Objective(\"val_x_MEE\", direction=\"min\"),\n",
    "               kt.Objective(\"val_y_MEE\", direction=\"min\")],\n",
    "    max_consecutive_failed_trials=1,\n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "# Tune the model\n",
    "keras_tuner.search(train_dataset, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMrm6kFpMHNi"
   },
   "outputs": [],
   "source": [
    "# Summary results\n",
    "keras_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "165vVq-2V9Yl"
   },
   "source": [
    "### **Fine-grained GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5lBEuOfV8yE"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  model = tfdf.keras.RandomForestModel(\n",
    "      min_examples=hp.Choice(\"min_examples\", [1, 2, 3]),\n",
    "      max_depth=hp.Choice(\"max_depth\", [15, 20, 25, 30]),\n",
    "      num_candidate_attributes_ratio=hp.Fixed(\"num_candidate_attributes_ratio\", 0.2),\n",
    "      num_trees = hp.Choice(\"num_trees\", [500, 750, 1000]),\n",
    "      multitask=mulitask\n",
    "  )\n",
    "\n",
    "  # Optimize the model MEE as computed on the validation dataset.\n",
    "  model.compile(metrics=[MEE])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7yVCb-iYbJC"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define Keras Tuner\n",
    "keras_tuner = kt.GridSearch(\n",
    "    build_model,\n",
    "    # we will minimize the sum of all the objectives to minimize\n",
    "    objective=[kt.Objective(\"val_x_MEE\", direction=\"min\"),\n",
    "               kt.Objective(\"val_y_MEE\", direction=\"min\")],\n",
    "    max_consecutive_failed_trials=1,\n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "# Tune the model\n",
    "keras_tuner.search(train_dataset, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9NX47DumAXB"
   },
   "outputs": [],
   "source": [
    "# Summary results\n",
    "keras_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wa9ME2xGWr0j"
   },
   "outputs": [],
   "source": [
    "# Top 5 Models\n",
    "top5_hps = keras_tuner.get_best_hyperparameters(5)\n",
    "\n",
    "for i, hps in enumerate(top5_hps):\n",
    "  print(f\"model{i}: {hps.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKdqE5dxXnth"
   },
   "outputs": [],
   "source": [
    "# Best Model\n",
    "best_hps = top5_hps[0].values\n",
    "print(\"Best hyper-parameters:\", best_hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmopDdT7wuLw"
   },
   "source": [
    "---\n",
    "## **K-Fold Cross Validation best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHpOEFNiw4qs"
   },
   "outputs": [],
   "source": [
    "# Val MEE on the individual folds\n",
    "MEE_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Run a 5-folds cross-validation\n",
    "for  fold_idx, (train_indices, val_indices) in enumerate(kfold.split(design)):\n",
    "  print(f\"Running fold {fold_idx+1}\")\n",
    "\n",
    "  # Extract the training and testing examples\n",
    "  X_train , y_train = design.iloc[train_indices, :-2], design.iloc[train_indices, -2:]\n",
    "  X_val , y_val = design.iloc[val_indices, :-2], design.iloc[val_indices, -2:]\n",
    "\n",
    "  y_train_dict = {\n",
    "     'x': y_train['x'].values,\n",
    "     'y': y_train['y'].values\n",
    "     }\n",
    "\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train_dict)).batch(64)\n",
    "\n",
    "  # Multitask Regression (model with multiple outputs trained to predict different labels)\n",
    "  mulitask = [tfdf.keras.MultiTaskItem(label=t, task=tfdf.keras.Task.REGRESSION) for t in ['x', 'y']]\n",
    "\n",
    "  # Configure the model\n",
    "  model = tfdf.keras.RandomForestModel(**best_hps, multitask=mulitask)\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(metrics=[MEE])\n",
    "\n",
    "  # Train the model\n",
    "  model.fit(train_dataset, verbose=False)\n",
    "\n",
    "  # Evaluate the model\n",
    "  val_pred = model.predict(X_val.values, verbose=0)\n",
    "  val_pred = pd.DataFrame({k:v.ravel() for k, v in val_pred.items()})\n",
    "  y_pred = tf.convert_to_tensor(val_pred, dtype=tf.double)\n",
    "  y_true = tf.convert_to_tensor(y_val, dtype=tf.double)\n",
    "  mee = float(MEE(y_true, y_pred))\n",
    "  print(f\"MEE: {mee}\")\n",
    "\n",
    "  MEE_per_fold.append(mee)\n",
    "\n",
    "\n",
    "print(f\"Mean: {mean(MEE_per_fold)}\")\n",
    "print(f\"Stdev: {stdev(MEE_per_fold)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-68dOj8R6RGj"
   },
   "source": [
    "---\n",
    "## **Model Assessment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w16SrTuz6h55"
   },
   "outputs": [],
   "source": [
    "# Re-instantiate the best model\n",
    "best_model = tfdf.keras.RandomForestModel(min_examples= 2,\n",
    "                                          max_depth= 20,\n",
    "                                          num_candidate_attributes_ratio= 0.2,\n",
    "                                          num_trees= 500,\n",
    "                                          multitask=mulitask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8xfz-RvYmI4"
   },
   "outputs": [],
   "source": [
    "# Re-Train the model on Design set\n",
    "best_model.fit(design_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTDJcetWYmFl"
   },
   "outputs": [],
   "source": [
    "# Summary results\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ura-qD-HTCV0"
   },
   "outputs": [],
   "source": [
    "# Prediction on Design set\n",
    "design_pred = best_model.predict(X_design.values, verbose=0)\n",
    "design_pred = pd.DataFrame({k:v.ravel() for k,v in design_pred.items()})\n",
    "y_pred_design = tf.convert_to_tensor(design_pred, dtype=tf.double)\n",
    "y_true = tf.convert_to_tensor(y_design, dtype=tf.double)\n",
    "mee_design = float(MEE(y_true, y_pred_design))\n",
    "print(f'Design MEE: {mee_design}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWMsSJlF6h9c"
   },
   "outputs": [],
   "source": [
    "# Prediction on Test set\n",
    "test_pred = best_model.predict(X_test.values, verbose=0)\n",
    "test_pred = pd.DataFrame({k:v.ravel() for k, v in test_pred.items()})\n",
    "y_pred_TS = tf.convert_to_tensor(test_pred, dtype=tf.double)\n",
    "y_true = tf.convert_to_tensor(y_test, dtype=tf.double)\n",
    "mee_test = float(MEE(y_true, y_pred_TS))\n",
    "print(f\"Test MEE: {mee_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxKg0QFgZyd5"
   },
   "source": [
    "## **Prediction Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUQCjwWFaBO8"
   },
   "outputs": [],
   "source": [
    "# y prediction\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.scatterplot(x=y_test['x'], y=y_test['y'], color='k', label='y_true')\n",
    "sns.scatterplot(x=y_test['x'], y=y_pred_TS[:, 1], color='g', label='y_pred')\n",
    "plt.title('Random Forest y prediction', fontsize=14)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_71PJSsdTc1"
   },
   "outputs": [],
   "source": [
    "# x prediction\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.scatterplot(x=y_test['x'], y=y_test['y'], color='k', label='x_true')\n",
    "sns.scatterplot(x=y_pred_TS[:, 0], y=y_test['y'], color='g', label='x_pred')\n",
    "plt.title('Random Forest x prediction', fontsize=14)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
